{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc22a440-6382-4764-82b4-bc3e84900342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2 as cv # so annoying in tutorials ngl\n",
    "import random\n",
    "%matplotlib qt\n",
    "from skimage import data, feature, exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207a34d3-ceb0-4b82-9a3b-2482c1838449",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = DataAnuncis('/home/adri/Desktop/cvc/data/tinder-historic/filenames.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e517a64-37be-4e2b-a286-5115b8a6e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70a44ed-9765-4b28-a72f-8314e73f948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample, cmap = 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d849d278-c64b-42f7-89b5-1269d945d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = files[2] # Takes the groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992f2938-9f76-4806-b1f0-25dc3c5eb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample, cmap = 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96385af8-f8cd-4d2a-8b1c-1878f058a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh = cv2.threshold(sample, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdff0533-f3a3-4911-9de9-8d177872af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(thresh, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b4c22f-6e74-422d-832c-3f06981503fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = thresh.shape[1]\n",
    "horizontal_size = cols // 30\n",
    "horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "horizontal = cv2.erode(thresh, horizontalStructure)\n",
    "horizontal = cv2.dilate(horizontal, horizontalStructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0037a89b-9e93-4c6e-9de9-6dc50dc296ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify size on vertical axis\n",
    "rows = thresh.shape[0]\n",
    "verticalsize = rows // 30\n",
    "# Create structure element for extracting vertical lines through morphology operations\n",
    "verticalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, verticalsize))\n",
    "# Apply morphology operations\n",
    "vertical = cv2.erode(thresh, verticalStructure)\n",
    "vertical = cv2.dilate(vertical, verticalStructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dee281e-8dd9-4764-8698-a6ffcfd85006",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.imshow(vertical*.5 + horizontal*.5, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68530dc9-cbce-45da-b618-d99542830abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anuncis = vertical*.7 + horizontal*.3 # What will we do when the blocks arent delimited by lines\n",
    "anuncis = ((anuncis - anuncis.min()) / (anuncis.max() - anuncis.min())) * 255\n",
    "ret, anuncis = cv2.threshold(anuncis.astype(np.uint8), 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "plt.imshow(anuncis, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ba188-25b9-4d8c-9d21-9d13bde0ba85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b81347f-44b6-48f2-afca-4566b8858b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "anuncis = ~ anuncis\n",
    "plt.imshow(anuncis, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb379592-f3a8-4411-a189-2607bc97b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv.HoughLinesP(anuncis, 1, np.pi / 180, 150, 10, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "922d61c3-253c-4995-b7c3-8ac33242a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = np.zeros_like(sample)\n",
    "for i in range(0, len(lines)):\n",
    "    l = lines[i][0]\n",
    "    src = cv.line(src, (l[0], l[1]), (l[2], l[3]), (155,155,255), 3, cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d74bd054-c37a-4d8d-812c-4ddfa614f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(src, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f8f060a-8874-48f5-8aeb-e674347acf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n"
     ]
    }
   ],
   "source": [
    "contours, hierarchy = cv2.findContours(anuncis, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb26c8-b62c-4cde-b6e3-ecc560696e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21e2f451-d8dc-41da-9ab0-fd3c0f758f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = np.zeros_like(sample.copy())\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    # Drawing a rectangle on copied image\n",
    "    sample2 = cv2.rectangle(sample2, (x, y), (x + w, y + h), (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bf631bc-3cd9-404b-ab66-73767b3347b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample2*0.8 + sample*0.2, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc015587-bad9-4f36-8d05-0c2f030da926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(anuncis,np.ones((5, 5)),iterations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ac90db2-ca5d-4d0f-8844-4ebd2603cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(~dilation, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f58bdd6-662a-4067-b001-d3d0fc2767df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a37dcceb-5d70-4c0a-934b-c837507f5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = np.zeros_like(sample.copy())\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    # Drawing a rectangle on copied image\n",
    "    sample2 = cv2.rectangle(sample2, (x, y), (x + w, y + h), (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5f6e92d-142c-452c-95e6-382531cc9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample2*0.8 + sample*0.2, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7696b96-4e94-4e40-bb98-eb7e7ea96aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = sample2*0.8 + sample*0.2\n",
    "img = ((img - img.min())/(img.max() - img.min()))*255\n",
    "cv2.imwrite('res1.png', img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaa5b127-3e69-4cf7-b767-bffcd873f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes(sample, prop_vertical = 0.7, iter_dilate = 5, dilate_size = 4):\n",
    "    \n",
    "    \n",
    "    ret, thresh = cv2.threshold(sample, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    cols = thresh.shape[1]\n",
    "    horizontal_size = cols // 30\n",
    "    horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "    horizontal = cv2.erode(thresh, horizontalStructure)\n",
    "    horizontal = cv2.dilate(horizontal, horizontalStructure)\n",
    "\n",
    "    # Specify size on vertical axis\n",
    "    rows = thresh.shape[0]\n",
    "    verticalsize = rows // 30\n",
    "    # Create structure element for extracting vertical lines through morphology operations\n",
    "    verticalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, verticalsize))\n",
    "    # Apply morphology operations\n",
    "    vertical = cv2.erode(thresh, verticalStructure)\n",
    "    vertical = cv2.dilate(vertical, verticalStructure)\n",
    "    \n",
    "    anuncis = vertical*prop_vertical + horizontal*(1 - prop_vertical) # What will we do when the blocks arent delimited by lines\n",
    "    anuncis = ((anuncis - anuncis.min()) / (anuncis.max() - anuncis.min())) * 255\n",
    "    ret, anuncis = cv2.threshold(anuncis.astype(np.uint8), 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    anuncis = ~ anuncis\n",
    "    \n",
    "    \n",
    "    dilation = cv2.dilate(anuncis,np.ones((dilate_size, dilate_size)),iterations = iter_dilate)\n",
    "    \n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    sample2 = np.zeros_like(sample.copy())\n",
    "    bbxs = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if 1: #w/h < 5 and w/h > 1:\n",
    "            bbxs.append((x, y, w, h))\n",
    "            # Drawing a rectangle on copied image\n",
    "            # We need a discard criteria\n",
    "            sample2 = cv2.rectangle(sample2, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "    img = sample2*0.8 + sample*0.2\n",
    "    img = ((img - img.min())/(img.max() - img.min()))*255\n",
    "\n",
    "    return img, bbxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de3d39e9-902a-49f6-b564-9ccc5ae5ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, bxs = get_boxes(sample)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8204d2b5-b8dd-4e02-a45e-730dd0e72593",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, bxs = get_boxes(files[2])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb5405-4d51-452b-a738-54b0612b9157",
   "metadata": {},
   "source": [
    "#### Detect titles with blops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb4ab6ce-b2c2-4a51-b5d0-895a60e6824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_blblurred(sample, blur_size = 11, conv_kernel = np.array([[0, 1, 0], [0, 1, 0], [0, 1, 0]]), erosion_size = 5, erosion_iter = 1, ret_boxes = False):\n",
    "    \n",
    "    ret, thresh = cv2.threshold(sample, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    blurred = cv2.GaussianBlur(thresh, (blur_size, blur_size), 10)\n",
    "    #blurred = cv2.Canny(thresh, 0, 100)\n",
    "    kernel = conv_kernel\n",
    "    kernel2 = kernel.T\n",
    "\n",
    "    convolved = cv2.filter2D(blurred, -1, kernel = kernel) + cv2.filter2D(blurred, -1, kernel = kernel2)\n",
    "    erosion = cv2.erode(convolved,np.ones(erosion_size),iterations = erosion_iter)\n",
    "    ret, thresh = cv2.threshold(erosion, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(~thresh)\n",
    "\n",
    "\n",
    "    # Map component labels to hue val, 0-179 is the hue range in OpenCV\n",
    "    label_hue = np.uint8(179*labels/np.max(labels))\n",
    "    blank_ch = 255*np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "\n",
    "    # Converting cvt to BGR\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # set bg label to black\n",
    "    labeled_img[label_hue==0] = 0\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2RGB)\n",
    "    output = np.zeros_like(sample).copy()\n",
    "\n",
    "    boxes = []\n",
    "    for i in range(0, num_labels):\n",
    "\n",
    "        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "        y = stats[i, cv2.CC_STAT_TOP]\n",
    "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        (cX, cY) = centroids[i]\n",
    "        if w*h < 1e4 or w/h < 1e-2 or h/w < 1e-2: continue # Hardcoded, do it from histogram\n",
    "        \n",
    "        \n",
    "        output = cv2.rectangle(output, (x, y), (x + w, y + h), (255, 255, 255), 3)\n",
    "        boxes.append((x, y, w, h))\n",
    "    \n",
    "    if ret_boxes: return output, boxes\n",
    "    return output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46e87b4f-8daa-4aaf-ae5b-ae99b6d206c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(find_blblurred(sample) + get_boxes(sample)[0], cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6703f1a-5a73-46f5-a6b8-c3c462ccbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(find_blblurred(sample, blur_size = 11, erosion_size=5, erosion_iter=1), cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00ddbb7b-0a2e-45a7-8ac5-161a99f5eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\r"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "for i in range(30):\n",
    "    print(i, end = '\\r')\n",
    "    s = files[i]\n",
    "    _, bbox = find_blblurred(s, ret_boxes=1)\n",
    "    for w in bbox:\n",
    "        stats.append([w[2]/w[3], w[2] * w[3]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f8b7252-3d16-4155-be48-aeb13eaf4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio, area = ([i[0] for i in stats], [i[1] for i in stats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f8e09a2-4985-4837-966d-5f945b75c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs, bins = np.histogram(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4c07bd4-4322-4ebd-a20e-dfada06d4af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3991,   13,   18,    6,    9,    6,    7,    1,    1,    1]),\n",
       " array([1.00154083e-02, 7.46553561e+00, 1.49210558e+01, 2.23765760e+01,\n",
       "        2.98320962e+01, 3.72876164e+01, 4.47431366e+01, 5.21986568e+01,\n",
       "        5.96541770e+01, 6.71096972e+01, 7.45652174e+01]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs, bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "656cd465-19db-4797-8bd8-0e1d22501faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "plt.imshow(find_blblurred(files[i]) + get_boxes(files[i])[0], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908a805-fa67-4f53-893e-58d2658269a3",
   "metadata": {},
   "source": [
    "## Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63fc4bf6-6239-46ae-a12d-1679d8611afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_detector(sample):\n",
    "    ret, thresh = cv2.threshold(sample, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    dst = cv.cornerHarris(thresh,10,3,0.04)\n",
    "    #ret, thresh = cv2.threshold(dst, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    dst = (dst - dst.min()) / (dst.max() - dst.min()) * 255\n",
    "    ret, thresh = cv2.threshold(dst.astype(np.uint8), 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    thresh = ~thresh\n",
    "    conv_kernel = np.array([[0, 1, 0], [0, 1, 0], [0, 1, 0]])\n",
    "    kernel = conv_kernel\n",
    "    kernel2 = kernel.T\n",
    "    convolved = cv2.filter2D(thresh, -1, kernel = kernel) + cv2.filter2D(thresh, -1, kernel = kernel2)\n",
    "    \n",
    "    \n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(convolved)\n",
    "\n",
    "\n",
    "    # Map component labels to hue val, 0-179 is the hue range in OpenCV\n",
    "    label_hue = np.uint8(179*labels/np.max(labels))\n",
    "    blank_ch = 255*np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "\n",
    "    # Converting cvt to BGR\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # set bg label to black\n",
    "    labeled_img[label_hue==0] = 0\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    output = np.zeros_like(sample).copy()\n",
    "\n",
    "    boxes = []\n",
    "    for i in range(0, num_labels):\n",
    "\n",
    "        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "        y = stats[i, cv2.CC_STAT_TOP]\n",
    "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        (cX, cY) = centroids[i]\n",
    "        if h*w < 1000: continue\n",
    "\n",
    "        output = cv2.rectangle(output, (x, y), (x + w, y + h), (255, 255, 255), 5)\n",
    "        boxes.append((x, y, w, h))\n",
    "    \n",
    "    return output, labeled_img, boxes, convolved\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02575a71-9f03-4a4c-9f3e-bf28a3dac1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o, i, bbxs, c = corner_detector(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "101abc09-4ac2-4162-adf9-7e8b58283e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i.astype(np.uint8)/255 * 0.5 + np.stack((sample, sample, sample)).transpose(1, 2, 0)/255 * 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f361514-7b16-4fa2-bf17-a5c1a4ed359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize = ( 32, 8 ))\n",
    "\n",
    "axs[2].imshow(i.astype(np.uint8)/255 * 0.3 + np.stack((o, o, o)).transpose(1, 2, 0)/255 * 0.7)\n",
    "axs[2].axis('off')\n",
    "\n",
    "axs[1].imshow(c, cmap = 'gray')\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[0].imshow(sample, cmap = 'gray')\n",
    "axs[0].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30856e16-e40c-408c-9dd7-e143760e31f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
